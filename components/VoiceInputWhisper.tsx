"use client";

/**
 * VoiceInputWhisper - iOSå¯¾å¿œã®éŸ³å£°å…¥åŠ›ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
 *
 * - MediaRecorder API ã§éŒ²éŸ³ï¼ˆiOS Safariå¯¾å¿œï¼‰
 * - Whisper API ã§æ–‡å­—èµ·ã“ã—
 * - Web Speech API ã¨åŒã˜ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
 *
 * ä½¿ç”¨ä¾‹:
 * ```tsx
 * <VoiceInputWhisper
 *   onTranscript={(text) => console.log(text)}
 *   apiEndpoint="/api/transcribe"
 * />
 * ```
 */

import { useState, useRef, useCallback, useEffect } from "react";

interface VoiceInputWhisperProps {
  onTranscript: (text: string) => void;
  onStartRecording?: () => void;
  onStopRecording?: () => void;
  onError?: (error: string) => void;
  apiEndpoint?: string;
  disabled?: boolean;
  maxDuration?: number; // æœ€å¤§éŒ²éŸ³æ™‚é–“ï¼ˆç§’ï¼‰
  className?: string;
}

type RecordingState = "idle" | "recording" | "processing";

export function VoiceInputWhisper({
  onTranscript,
  onStartRecording,
  onStopRecording,
  onError,
  apiEndpoint = "/api/transcribe",
  disabled = false,
  maxDuration = 60,
  className = "",
}: VoiceInputWhisperProps) {
  const [state, setState] = useState<RecordingState>("idle");
  const [duration, setDuration] = useState(0);
  const [isSupported, setIsSupported] = useState(true);

  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const chunksRef = useRef<Blob[]>([]);
  const timerRef = useRef<NodeJS.Timeout | null>(null);
  const streamRef = useRef<MediaStream | null>(null);

  // ã‚µãƒãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯
  useEffect(() => {
    const supported =
      typeof window !== "undefined" &&
      navigator.mediaDevices &&
      typeof MediaRecorder !== "undefined";
    setIsSupported(supported);
  }, []);

  // ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
  useEffect(() => {
    return () => {
      if (timerRef.current) {
        clearInterval(timerRef.current);
      }
      if (streamRef.current) {
        streamRef.current.getTracks().forEach((track) => track.stop());
      }
    };
  }, []);

  // éŒ²éŸ³é–‹å§‹
  const startRecording = useCallback(async () => {
    if (disabled || state !== "idle") return;

    try {
      // ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹å–å¾—
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          sampleRate: 16000,
        },
      });
      streamRef.current = stream;

      // MIMEã‚¿ã‚¤ãƒ—é¸æŠï¼ˆiOSå¯¾å¿œï¼‰
      const mimeType = MediaRecorder.isTypeSupported("audio/webm")
        ? "audio/webm"
        : MediaRecorder.isTypeSupported("audio/mp4")
        ? "audio/mp4"
        : "audio/wav";

      const mediaRecorder = new MediaRecorder(stream, { mimeType });
      mediaRecorderRef.current = mediaRecorder;
      chunksRef.current = [];

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          chunksRef.current.push(event.data);
        }
      };

      mediaRecorder.onstop = async () => {
        // ã‚¹ãƒˆãƒªãƒ¼ãƒ åœæ­¢
        stream.getTracks().forEach((track) => track.stop());

        // å‡¦ç†ä¸­çŠ¶æ…‹ã«
        setState("processing");

        // Blobã‚’ä½œæˆ
        const blob = new Blob(chunksRef.current, { type: mimeType });

        // Base64ã«å¤‰æ›
        const reader = new FileReader();
        reader.onloadend = async () => {
          const base64 = (reader.result as string).split(",")[1];

          try {
            // Whisper APIå‘¼ã³å‡ºã—
            const response = await fetch(apiEndpoint, {
              method: "POST",
              headers: {
                "Content-Type": "application/json",
              },
              body: JSON.stringify({
                audio: base64,
                mimeType,
              }),
            });

            if (!response.ok) {
              throw new Error(`API error: ${response.status}`);
            }

            const result = await response.json();

            if (result.success && result.data?.text) {
              onTranscript(result.data.text);
            } else if (result.error) {
              onError?.(result.error.message || "æ–‡å­—èµ·ã“ã—ã«å¤±æ•—ã—ã¾ã—ãŸ");
            }
          } catch (err) {
            console.error("Transcription error:", err);
            onError?.(err instanceof Error ? err.message : "ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ");
          } finally {
            setState("idle");
            setDuration(0);
          }
        };
        reader.readAsDataURL(blob);
      };

      // éŒ²éŸ³é–‹å§‹
      mediaRecorder.start(1000); // 1ç§’ã”ã¨ã«ãƒ‡ãƒ¼ã‚¿å–å¾—
      setState("recording");
      setDuration(0);
      onStartRecording?.();

      // ã‚¿ã‚¤ãƒãƒ¼é–‹å§‹
      timerRef.current = setInterval(() => {
        setDuration((prev) => {
          const next = prev + 1;
          if (next >= maxDuration) {
            stopRecording();
          }
          return next;
        });
      }, 1000);
    } catch (err) {
      console.error("Recording error:", err);
      onError?.("ãƒã‚¤ã‚¯ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒæ‹’å¦ã•ã‚Œã¾ã—ãŸ");
      setState("idle");
    }
  }, [disabled, state, apiEndpoint, maxDuration, onTranscript, onError, onStartRecording]);

  // éŒ²éŸ³åœæ­¢
  const stopRecording = useCallback(() => {
    if (timerRef.current) {
      clearInterval(timerRef.current);
      timerRef.current = null;
    }

    if (mediaRecorderRef.current && state === "recording") {
      mediaRecorderRef.current.stop();
      onStopRecording?.();
    }
  }, [state, onStopRecording]);

  // ãƒœã‚¿ãƒ³ã‚¯ãƒªãƒƒã‚¯
  const handleClick = useCallback(() => {
    if (state === "idle") {
      startRecording();
    } else if (state === "recording") {
      stopRecording();
    }
  }, [state, startRecording, stopRecording]);

  // æ™‚é–“ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
  const formatDuration = (sec: number) => {
    const m = Math.floor(sec / 60);
    const s = sec % 60;
    return `${m}:${s.toString().padStart(2, "0")}`;
  };

  if (!isSupported) {
    return (
      <button
        disabled
        className={`opacity-50 cursor-not-allowed ${className}`}
        title="ãŠä½¿ã„ã®ãƒ–ãƒ©ã‚¦ã‚¶ã¯éŸ³å£°å…¥åŠ›ã«å¯¾å¿œã—ã¦ã„ã¾ã›ã‚“"
      >
        ğŸ¤
      </button>
    );
  }

  return (
    <button
      onClick={handleClick}
      disabled={disabled || state === "processing"}
      className={`
        relative inline-flex items-center justify-center
        w-10 h-10 rounded-full
        transition-all duration-200
        ${state === "idle" ? "bg-gray-100 hover:bg-gray-200" : ""}
        ${state === "recording" ? "bg-red-500 animate-pulse" : ""}
        ${state === "processing" ? "bg-blue-500" : ""}
        ${disabled ? "opacity-50 cursor-not-allowed" : "cursor-pointer"}
        ${className}
      `}
      title={
        state === "idle"
          ? "ã‚¯ãƒªãƒƒã‚¯ã—ã¦éŒ²éŸ³é–‹å§‹"
          : state === "recording"
          ? "ã‚¯ãƒªãƒƒã‚¯ã—ã¦éŒ²éŸ³åœæ­¢"
          : "å‡¦ç†ä¸­..."
      }
    >
      {state === "idle" && <span className="text-lg">ğŸ¤</span>}
      {state === "recording" && (
        <>
          <span className="text-white text-lg">â¹</span>
          <span className="absolute -bottom-5 text-xs text-red-500 font-mono">
            {formatDuration(duration)}
          </span>
        </>
      )}
      {state === "processing" && (
        <span className="text-white text-sm animate-spin">â³</span>
      )}
    </button>
  );
}

export default VoiceInputWhisper;
